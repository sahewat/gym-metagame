{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-9147141fe572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmap_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmap_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'size' is not defined"
     ]
    }
   ],
   "source": [
    "map_shape=(64,64)\n",
    "x_dim, y_dim = size\n",
    "map_array = np.zeros(size)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8fdd208e6688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_anchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_anchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mn_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmap_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "n_anchors = 5\n",
    "start_idx = np.random.randint(64, size=(n_anchors, 2))\n",
    "n_moves = 20\n",
    "map_array = np.zeros(size)\n",
    "for idx in start_idx:\n",
    "    position = idx\n",
    "    map_array[idx[0], idx[1]] = 1\n",
    "    direction = np.random.choice([-1,1], 2)\n",
    "    \n",
    "    for move in range(n_moves):\n",
    "        should_move = True\n",
    "        while should_move:\n",
    "            if np.random.rand() > 0.95:\n",
    "                direction = np.random.choice([-1,0,1], 2)\n",
    "\n",
    "            possible_dir = position + direction \n",
    "            if not (np.sum(possible_dir > map_array.shape[0]-1) or np.sum(possible_dir < 0)):\n",
    "                if map_array[possible_dir[0], possible_dir[1]] == 1:\n",
    "                    continue\n",
    "                position = possible_dir\n",
    "                map_array[possible_dir[0], possible_dir[1]] = 1\n",
    "                should_move = False\n",
    "        \n",
    "plt.imshow(map_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_map(map_shape=(16,16)):\n",
    "    x_dim, y_dim = map_shape\n",
    "    map_array = np.zeros(map_shape)\n",
    "\n",
    "    n_anchors = 6\n",
    "    start_idx = np.random.randint(map_shape[0], size=(n_anchors, 2))\n",
    "    n_moves = 20\n",
    "    map_array = np.zeros(map_shape)\n",
    "    start_position = map_array[0,0] = 2\n",
    "    end_position = map_array[-1,-1] = 3\n",
    "\n",
    "    for idx in start_idx:\n",
    "        position = idx\n",
    "        map_array[idx[0]-2:idx[0], idx[1]-2:idx[1]] = 1\n",
    "\n",
    "    plt.imshow(map_array)\n",
    "    return map_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0cccad0efe27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-539e926e00cb>\u001b[0m in \u001b[0;36mrandom_map\u001b[0;34m(map_shape)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmap_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "random_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import baselines.ppo2\n",
    "import baselines.common \n",
    "import baselines.common.vec_env\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baselines.common.vec_env.VecEnv"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines.common.vec_env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT = 0\n",
    "UP = 3\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "\n",
    "class GridEnv():\n",
    "    def __init__(self):\n",
    "        self.state = random_map()\n",
    "        self.start_state = [0,0]\n",
    "        self.position = [0,0]\n",
    "        self.end_state = [-1,-1]\n",
    "        self.path = [self.start_state]\n",
    "        \n",
    "    def _move(self, row, col, a):\n",
    "            ncol = nrow = self.state.shape[0]\n",
    "            new_row = row\n",
    "            new_col = col\n",
    "            if a==0: # left\n",
    "                new_col = max(col-1,0)\n",
    "            elif a==1: # down\n",
    "                new_row = min(row+1,nrow-1)\n",
    "            elif a==2: # right\n",
    "                new_col = min(col+1,ncol-1)\n",
    "            elif a==3: # up\n",
    "                new_row = max(row-1,0)\n",
    "            return (new_row, new_col)\n",
    "        \n",
    "    def step(self, action):\n",
    "        new_position = self._move(*self.position, action)\n",
    "        #current_map[new_position[0], new_position[1]] = 0\n",
    "        if self.state[new_position[1], new_position[0]] == 1:\n",
    "            print(new_position)\n",
    "            new_position = self.position\n",
    "            assert new_position == self.position\n",
    "        self.path.append(new_position)\n",
    "            \n",
    "        self.position = new_position\n",
    "        if self.state[new_position[0], new_position[1]] == 3:\n",
    "            complete = True\n",
    "            print(\"DONE\")\n",
    "        else:\n",
    "            complete = False\n",
    "        \n",
    "        return new_position, complete\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        current_map = self.state.copy()\n",
    "        #current_map[self.position[0], self.position[1]] = 4\n",
    "        path = np.array(self.path)\n",
    "        plt.plot(*path.T, 'o')\n",
    "        plt.imshow(current_map, cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "59\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3e854bbb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "env = GridEnv()\n",
    "probs = np.array([2,2,5,5])\n",
    "probs =  probs/probs.sum()\n",
    "\n",
    "for i in range(10000):\n",
    "    choice = np.random.choice([LEFT, UP, RIGHT, DOWN], p=probs)\n",
    "    out, complete = env.step(choice)\n",
    "    if complete:\n",
    "        break\n",
    "    \n",
    "env.render()\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probs = np.array([2,2,5,5])\n",
    "probs =  probs/probs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14285714, 0.14285714, 0.35714286, 0.35714286])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 3.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, map_size):\n",
    "        super(Policy, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, bias=True, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(4, 4, kernel_size=3, bias=True, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(4, 1, kernel_size=1, bias=True),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(256, 4)\n",
    "\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_int = self.net(x).view(1, -1)\n",
    "        x_int = self.fc(x_int)\n",
    "        \n",
    "        action_scores = x_int\n",
    "        return F.softmax(action_scores, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = Policy((16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnet = nn.Conv2d(1, 4, kernel_size=3, bias=True, padding=1)\n",
    "test_input = torch.Tensor(1, 1, 16, 16).uniform_(0, 1)\n",
    "test_input_v = Variable(test_input)\n",
    "out = test_net(test_input_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 10), False)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = torch.distributions.Categorical(probs=out)\n",
    "choice = actions.sample().data.numpy()\n",
    "env.step(choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378, -0.10050378,\n",
       "       -0.10050378, -0.10050378, -0.10050378, -0.10050378,  9.89949622])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = np.zeros(100)\n",
    "rewards[-1] = 10\n",
    "rewards - rewards.mean() / (rewards.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 4D tensor as input, got 2D tensor instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-316-1f06bd24bb58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_input_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Reinforce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-310-41ca993160e5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#x_int = F.dropout(0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 282\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected 4D tensor as input, got {}D tensor instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     f = _ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 4D tensor as input, got 2D tensor instead."
     ]
    }
   ],
   "source": [
    "#test_input = torch.Tensor(1, 4).uniform_(0, 1)\n",
    "#test_input_v = Variable(test_input)\n",
    "#out = test_net(test_input_v)\n",
    "# Reinforce\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-d9b5383a56df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolict_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Note that this is equivalent to what used to be called multinomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_network' is not defined"
     ]
    }
   ],
   "source": [
    "polict_network = test_network\n",
    "probs = policy_network(state)\n",
    "# Note that this is equivalent to what used to be called multinomial\n",
    "m = Categorical(probs)\n",
    "action = m.sample()\n",
    "next_state, reward = env.step(action)\n",
    "loss = -m.log_prob(action) * reward\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.LongTensor of size 1]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'action_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-b5bed90b49be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maction_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'action_scores' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/TH/generic/THTensorRandom.c:280",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-ac18adce964f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/distributions.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmultinomial\u001b[0;34m(self, num_samples, replacement)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/stochastic.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, probs, num_samples, with_replacement)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_replacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_replacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_non_differentiable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/TH/generic/THTensorRandom.c:280"
     ]
    }
   ],
   "source": [
    "actions.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')\n",
    "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n",
    "                    help='discount factor (default: 0.99)')\n",
    "parser.add_argument('--seed', type=int, default=543, metavar='N',\n",
    "                    help='random seed (default: 543)')\n",
    "parser.add_argument('--render', default=True, action='store_true',\n",
    "                    help='render the environment')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='interval between training status logs (default: 10)')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 128)\n",
    "        self.affine2 = nn.Linear(128, 2)\n",
    "\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.affine2(x)\n",
    "        return F.softmax(action_scores, dim=1)\n",
    "\n",
    "\n",
    "policy = Policy()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    probs = policy(Variable(state))\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    policy.saved_log_probs.append(m.log_prob(action))\n",
    "    return action.data[0]\n",
    "\n",
    "\n",
    "def finish_episode():\n",
    "    R = 0\n",
    "    policy_loss = []\n",
    "    rewards = []\n",
    "    for r in policy.rewards[::-1]:\n",
    "        R = r + args.gamma * R\n",
    "        rewards.insert(0, R)\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)\n",
    "    for log_prob, reward in zip(policy.saved_log_probs, rewards):\n",
    "        policy_loss.append(-log_prob * reward)\n",
    "    optimizer.zero_grad()\n",
    "    policy_loss = torch.cat(policy_loss).sum()\n",
    "    policy_loss.backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_log_probs[:]\n",
    "\n",
    "\n",
    "def main():\n",
    "    running_reward = 10\n",
    "    for i_episode in count(1):\n",
    "        state = env.reset()\n",
    "        for t in range(100):  # Don't infinite loop while learning\n",
    "            action = select_action(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            if args.render:\n",
    "                env.render()\n",
    "            policy.rewards.append(reward)\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        running_reward = running_reward * 0.99 + t * 0.01\n",
    "        finish_episode()\n",
    "        if i_episode % args.log_interval == 0:\n",
    "            print('Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}'.format(\n",
    "                i_episode, t, running_reward))\n",
    "        if running_reward > env.spec.reward_threshold:\n",
    "            print(\"Solved! Running reward is now {} and \"\n",
    "                  \"the last episode runs to {} time steps!\".format(running_reward, t))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')\n",
    "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n",
    "                    help='discount factor (default: 0.99)')\n",
    "parser.add_argument('--seed', type=int, default=543, metavar='N',\n",
    "                    help='random seed (default: 543)')\n",
    "parser.add_argument('--render', default=True, action='store_true',\n",
    "                    help='render the environment')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='interval between training status logs (default: 10)')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 128)\n",
    "        self.affine2 = nn.Linear(128, 2)\n",
    "\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.affine2(x)\n",
    "        return F.softmax(action_scores, dim=1)\n",
    "\n",
    "\n",
    "policy = Policy()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    probs = policy(Variable(state))\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    policy.saved_log_probs.append(m.log_prob(action))\n",
    "    return action.data[0]\n",
    "\n",
    "\n",
    "def finish_episode():\n",
    "    R = 0\n",
    "    policy_loss = []\n",
    "    rewards = []\n",
    "    for r in policy.rewards[::-1]:\n",
    "        R = r + args.gamma * R\n",
    "        rewards.insert(0, R)\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)\n",
    "    for log_prob, reward in zip(policy.saved_log_probs, rewards):\n",
    "        policy_loss.append(-log_prob * reward)\n",
    "    optimizer.zero_grad()\n",
    "    policy_loss = torch.cat(policy_loss).sum()\n",
    "    policy_loss.backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_log_probs[:]\n",
    "\n",
    "\n",
    "def main():\n",
    "    running_reward = 10\n",
    "    for i_episode in count(1):\n",
    "        state = env.reset()\n",
    "        for t in range(100):  # Don't infinite loop while learning\n",
    "            action = select_action(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            if args.render:\n",
    "                env.render()\n",
    "            policy.rewards.append(reward)\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        running_reward = running_reward * 0.99 + t * 0.01\n",
    "        finish_episode()\n",
    "        if i_episode % args.log_interval == 0:\n",
    "            print('Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}'.format(\n",
    "                i_episode, t, running_reward))\n",
    "        if running_reward > env.spec.reward_threshold:\n",
    "            print(\"Solved! Running reward is now {} and \"\n",
    "                  \"the last episode runs to {} time steps!\".format(running_reward, t))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
